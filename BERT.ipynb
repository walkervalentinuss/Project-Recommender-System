{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4524838-c9b1-4227-978a-b6bf6fee1cfe",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Project Recommender System\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Kode Mata Kuliah</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\">12S3205</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Nama Mata Kuliah</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\">Sistem Rekomendasi</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Topik</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\"><i>Sistem Rekomendasi untuk Pariwisata Toba</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Mahasiswa 1</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\"><i>12S21012 - Walker Valentinus Simanjuntak</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Mahasiswa 2</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\"><i>12S21021 - Naomi Elena Lumbanraja</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Mahasiswa 3</td>\n",
    "        <td style=\"text-align:left\">:</td>\n",
    "        <td style=\"text-align:left\"><i>12S21033 - Sry Deviani Tambunan</i></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427357ab-3454-41b7-adaf-378051adfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114e7872-6b38-45f5-954c-872bca8f0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f12254-7dc3-46e7-9fac-ee860038b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data\\Tempat-Wisata-Toba-Preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e4a327-9737-48f3-9225-a4ebfbc7c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43226, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8860ded2-a35f-48bc-973c-057b9692acb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'address', 'PlaceID',\n",
       "       'Nama_tempat_wisata', 'Category', 'ReviewerId', 'Rating', 'Reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1502c80b-77ef-4ff8-a52c-a72482545841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>item_id</th>\n",
       "      <th>Nama_tempat_wisata</th>\n",
       "      <th>Category</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...</td>\n",
       "      <td>0</td>\n",
       "      <td>PASIR PUTIH LUMBAN BULBUL</td>\n",
       "      <td>Wisata Bahari</td>\n",
       "      <td>1.11909e+20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bagus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...</td>\n",
       "      <td>0</td>\n",
       "      <td>PASIR PUTIH LUMBAN BULBUL</td>\n",
       "      <td>Wisata Bahari</td>\n",
       "      <td>1.13072e+20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sangat menyenagkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...</td>\n",
       "      <td>0</td>\n",
       "      <td>PASIR PUTIH LUMBAN BULBUL</td>\n",
       "      <td>Wisata Bahari</td>\n",
       "      <td>1.06173e+20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bebas foto dimana aja cuma 2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...</td>\n",
       "      <td>0</td>\n",
       "      <td>PASIR PUTIH LUMBAN BULBUL</td>\n",
       "      <td>Wisata Bahari</td>\n",
       "      <td>1.14239e+20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>amazing pengen kesini lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...</td>\n",
       "      <td>0</td>\n",
       "      <td>PASIR PUTIH LUMBAN BULBUL</td>\n",
       "      <td>Wisata Bahari</td>\n",
       "      <td>1.04743e+20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>jalan menuju lokasi perlu diperhatikan oleh pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "1             1           1   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "6             6           6   \n",
       "8             8           8   \n",
       "\n",
       "                                             address item_id  \\\n",
       "1  Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...       0   \n",
       "3  Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...       0   \n",
       "4  Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...       0   \n",
       "6  Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...       0   \n",
       "8  Jl. Sibola Hotang, Sibola Hotangsas, Kec. Bali...       0   \n",
       "\n",
       "          Nama_tempat_wisata       Category      user_id  rating  \\\n",
       "1  PASIR PUTIH LUMBAN BULBUL  Wisata Bahari  1.11909e+20     5.0   \n",
       "3  PASIR PUTIH LUMBAN BULBUL  Wisata Bahari  1.13072e+20     5.0   \n",
       "4  PASIR PUTIH LUMBAN BULBUL  Wisata Bahari  1.06173e+20     5.0   \n",
       "6  PASIR PUTIH LUMBAN BULBUL  Wisata Bahari  1.14239e+20     5.0   \n",
       "8  PASIR PUTIH LUMBAN BULBUL  Wisata Bahari  1.04743e+20     3.0   \n",
       "\n",
       "                                             Reviews  \n",
       "1                                              bagus  \n",
       "3                                 sangat menyenagkan  \n",
       "4                      bebas foto dimana aja cuma 2k  \n",
       "6                         amazing pengen kesini lagi  \n",
       "8  jalan menuju lokasi perlu diperhatikan oleh pe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'ReviewerId': 'user_id', 'PlaceID': 'item_id', 'Rating': 'rating'})\n",
    "data['user_id'] = data['user_id'].astype(str)\n",
    "data['item_id'] = data['item_id'].astype(str)\n",
    "data['rating'] = data['rating'].astype(float)\n",
    "data.dropna(inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aaa9b2a-832c-4c25-8569-701ae58bd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22166, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e46a76-2079-413e-bb39-83a2a882db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (15638, 9)\n",
      "Validation data size: (3203, 9)\n",
      "Test data size: (3325, 9)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into 85% training+validation and 15% test\n",
    "train_val_data, test_data = train_test_split(data, test_size=0.15, random_state=42)\n",
    "# Step 2: Define validation size as 17% of train+validation, rounded up\n",
    "val_size = int(len(train_val_data) * 0.17) + 1\n",
    "# Step 3: Split 85% data into training (about 70% of original) and validation (about 15% of original)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=val_size, random_state=42)\n",
    "# Check sizes\n",
    "print(f\"Train data size: {train_data.shape}\")\n",
    "print(f\"Validation data size: {val_data.shape}\")\n",
    "print(f\"Test data size: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d06ef-23ef-41c5-9469-b52eb321a291",
   "metadata": {},
   "source": [
    "Penjelasan Langkah-Langkah\n",
    "\n",
    "1. Membagi Data Menjadi Training+Validation dan Test:\n",
    "   - train_test_split(data, test_size=0.15, random_state=42): Fungsi ini digunakan untuk membagi dataset awal menjadi dua bagian, yaitu:\n",
    "     - 85% untuk Training+Validation (train_val_data)\n",
    "     - 15% untuk Test (test_data)\n",
    "   - Pembagian ini bertujuan untuk menyisihkan sebagian data sebagai data uji akhir (test data), yang akan digunakan untuk mengevaluasi kinerja model setelah tahap pelatihan dan tuning selesai.\n",
    "\n",
    "2. Menentukan Ukuran Data Validation:\n",
    "   - val_size = int(len(train_val_data) * 0.17) + 1:\n",
    "     - Setelah membagi data awal menjadi training+validation dan test, kita menentukan bahwa 17% dari train_val_data akan digunakan sebagai data validasi.\n",
    "     - Penambahan +1 memastikan bahwa ukuran validasi selalu dibulatkan ke atas, agar kita mendapatkan sekitar 17% dari\n",
    "   - train_val_data sebagai data validasi.\n",
    "\n",
    "3. Membagi Training+Validation Menjadi Training dan Validation:\n",
    "   - train_test_split(train_val_data, test_size=val_size, random_state=42): Fungsi ini membagi train_val_data menjadi dua bagian:\n",
    "     - Training Data (train_data), sekitar 70% dari data asli.\n",
    "     - Validation Data (val_data), sekitar 15% dari data asli.\n",
    "   - Pembagian ini bertujuan untuk menyediakan data validasi yang akan digunakan untuk tuning model, misalnya dalam memilih hyperparameter.\n",
    "\n",
    "4. Menampilkan Ukuran Setiap Subset:\n",
    "   - print(f\"Train data size: {train_data.shape}\"): Menampilkan ukuran data training.\n",
    "   - print(f\"Validation data size: {val_data.shape}\"): Menampilkan ukuran data validasi.\n",
    "   - print(f\"Test data size: {test_data.shape}\"): Menampilkan ukuran data uji.ilkan ukuran data uji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3bbb83-299b-473a-a1f1-77d84026fa67",
   "metadata": {},
   "source": [
    "Analisis Pembagian Data\n",
    "1. Pembagian data yang dilakukan di sini cukup standar dalam machine learning dan sangat penting untuk memastikan bahwa model tidak overfitting atau underfitting.\n",
    "2. Training Set (70%) digunakan untuk melatih model, mempelajari pola-pola dalam data, dan mengoptimalkan parameter model.\n",
    "3. Validation Set (15%) menyediakan data yang terpisah dari training untuk tuning hyperparameter dan memilih model terbaik. Ini mencegah model dari overfitting pada training data karena kita melakukan evaluasi selama proses tuning pada data yang belum pernah dilihat oleh model.\n",
    "4. Test Set (15%) adalah bagian dari data yang sepenuhnya terpisah, digunakan untuk mengevaluasi performa akhir model setelah proses pelatihan dan tuning selesai. Ini memberikan gambaran yang lebih objektif tentang bagaimana model akan berkinerja pada data baru atau data di dunia nyata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882471cc-d44b-43e9-99f8-d58a445deeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Pembanding CBF - (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753075ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: requests in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from sacremoses->transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from sacremoses->transformers) (1.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\walkervalentinus\\appdata\\roaming\\python\\python311\\site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers) (2.8.2)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/991.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/991.5 kB ? eta -:--:--\n",
      "   -------------------- ----------------- 524.3/991.5 kB 989.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\ProgramData\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2603f2-5333-4a7e-a90b-dcbe5adfe8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertModel' from 'transformers' (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BertModel' from 'transformers' (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436c541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d01c7-b2a2-4eae-ba74-5c8f6e361718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess dataset\n",
    "data = pd.read_csv(\"Tempat-Wisata-Toba-Preprocessing.csv\")\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the dataset\n",
    "file_path_new = 'Tempat-Wisata-Toba-Preprocessing.csv'\n",
    "\n",
    "# Load the dataset\n",
    "dataset_new = pd.read_csv(file_path_new)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "dataset_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c769e40-709e-4da7-ac6f-cff109704a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'Nama_tempat_wisata' and 'Reviews' to form the content description\n",
    "dataset_new['description'] = dataset_new['Nama_tempat_wisata'] + \" \" + dataset_new['Reviews'].fillna('')\n",
    "\n",
    "# Display the updated dataset\n",
    "dataset_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a206c4b-a423-4530-9893-b5f09172f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'PlaceID'\n",
    "dataset_new = dataset_new.drop_duplicates(subset='PlaceID')\n",
    "\n",
    "# Display the dataset to verify changes\n",
    "dataset_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a51fe3-3350-43bc-a155-bcbfc7a380da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db219ccd-65d7-4f19-a25e-62da096a066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Function to get BERT embeddings for text\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)  # CLS token\n",
    "    return embedding.numpy()# Step 4: Compute embeddings for each place\n",
    "dataset_new['embedding'] = dataset_new['description'].apply(get_bert_embedding)\n",
    "\n",
    "# Display the updated dataset\n",
    "dataset_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cd6ae-6684-49c0-b67f-8f13bad2c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute embeddings for each place\n",
    "dataset_new['embedding'] = dataset_new['description'].apply(get_bert_embedding)\n",
    "\n",
    "# Display the updated dataset\n",
    "dataset_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f45d1-5972-4c5e-84ec-4ff340c5c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build similarity matrix\n",
    "embeddings = np.array(dataset_new['embedding'].tolist())\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Verify the similarity matrix\n",
    "similarity_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7dad6-20a1-4ad1-8053-025db544cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Recommendation function\n",
    "def recommend_places(place_id, dataset, similarity_matrix, top_n=5):\n",
    "    try:\n",
    "        place_index = dataset[dataset['PlaceID'] == place_id].index[0]\n",
    "        similarity_scores = similarity_matrix[place_index]\n",
    "        top_indices = similarity_scores.argsort()[-top_n-1:-1][::-1]  # Exclude itself\n",
    "        recommendations = dataset.iloc[top_indices]\n",
    "        return recommendations[['PlaceID', 'Nama_tempat_wisata', 'Category']]\n",
    "    except IndexError:\n",
    "        return \"Place ID not found in the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efddd515-754d-4bd3-9af5-1497662ab212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get recommendations for a specific place\n",
    "place_id = 0  # Replace with a valid PlaceID from your dataset\n",
    "recommendations = recommend_places(place_id, dataset, similarity_matrix, top_n=5)\n",
    "print(f\"Top recommendations for PlaceID {place_id}:\\n\", recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934148f4-6b00-496e-a8ce-6845ba35351a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
